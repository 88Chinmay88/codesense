name: <CodeSense?>

on:
  push:
    branches: [ main, master, development ]
  pull_request:
    branches: [ main, master, development ]

jobs:
  ai-code-review:
    runs-on: ubuntu-latest
    
    env:
      GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
      CODE_REVIEW_PROMPT: |
        Respond in a JSON format for the following code review task. The model MUST return a structured JSON output with detailed explanations for each section. The output MUST adhere to the following format and include dynamically computed values, findings, and recommendations.

        Analyze the following code and provide a detailed review in this exact JSON structure:
        {
            "structureAnalysis": {
                "architecture": {
                    "score": number,
                    "findings": [{
                        "aspect": string,
                        "evaluation": string,
                        "recommendation": string,
                        "explanation": string
                    }],
                    "explanation": string
                },
                "codeQuality": {
                    "cyclomaticComplexity": string,
                    "documentationScore": number,
                    "cohesionScore": number,
                    "findings": [],
                    "explanation": string
                }
            },
            "implementationReview": {
                "errorHandling": {
                    "score": number,
                    "issues": [{
                        "issue": string,
                        "recommendation": string,
                        "explanation": string
                    }],
                    "explanation": string
                },
                "performance": {
                    "timeComplexity": string,
                    "spaceComplexity": string,
                    "bottlenecks": [{
                        "function": string,
                        "issue": string,
                        "recommendation": string,
                        "explanation": string
                    }],
                    "explanation": string
                }
            },
            "bestPractices": {
                "codeStyle": {
                    "score": number,
                    "violations": [],
                    "explanation": string
                },
                "security": {
                    "score": number,
                    "vulnerabilities": [{
                        "issue": string,
                        "recommendation": string,
                        "explanation": string
                    }],
                    "explanation": string
                }
            },
            "recommendations": {
                "priority": string,
                "items": [{
                    "category": string,
                    "title": string,
                    "description": string,
                    "severity": string,
                    "explanation": string
                }],
                "explanation": string
            },
            "metrics": {
                "overallScore": number,
                "qualityScore": number,
                "securityScore": number,
                "performanceScore": number,
                "maintainabilityScore": number,
                "explanation": string
            },
            "corrections": {
                "hasCorrections": boolean,
                "correctedCode": string,
                "changes": [{
                    "type": string,
                    "location": string,
                    "original": string,
                    "correction": string,
                    "explanation": string
                }],
                "explanation": string
            }
        }
    
    steps:
    - name: Checkout Repository
      uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'
    
    - name: Install Required Dependencies
      run: |
        sudo apt-get install jq -y
        python -m pip install --upgrade pip
        pip install requests pygments
    
    - name: Create Review Script
      run: |
        cat > review_code.py << 'EOF'
        import os
        import sys
        import requests
        import json
        import traceback
        import pygments
        from pygments.lexers import guess_lexer_for_filename

        GEMINI_API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent"
        API_KEY = os.getenv('GEMINI_API_KEY')
        HEADERS = {'Content-Type': 'application/json'}
        
        def review_code(file_content, filename, file_type):
            # Truncate very large files to prevent API limits
            max_content_length = 50000
            if len(file_content) > max_content_length:
                file_content = file_content[:max_content_length] + "\n\n... (content truncated)"
            
            prompt = f"""Please review the following {file_type} code from {filename}:

            {os.getenv('CODE_REVIEW_PROMPT')}

            Code to review:
            {file_content}
            """
            
            payload = {
                "contents": [{"parts": [{"text": prompt}]}]
            }
            
            try:
                # Send request to Gemini API
                response = requests.post(
                    f"{GEMINI_API_URL}?key={API_KEY}", 
                    headers=HEADERS, 
                    json=payload
                )
                
                if response.status_code == 200:
                    review_text = response.json()['candidates'][0]['content']['parts'][0]['text']
                    
                    # Attempt to parse the JSON to ensure it's valid
                    try:
                        json_review = json.loads(review_text)
                        return json.dumps(json_review, indent=2)
                    except json.JSONDecodeError:
                        # If JSON parsing fails, create a fallback JSON structure
                        return json.dumps({
                            "error": "Failed to parse AI review",
                            "raw_review": review_text
                        }, indent=2)
                else:
                    return json.dumps({
                        "error": f"API request failed: {response.text}"
                    }, indent=2)
            
            except Exception as e:
                return json.dumps({
                    "error": f"Review process failed: {str(e)}",
                    "traceback": traceback.format_exc()
                }, indent=2)
        
        def review_file(file_path):
            try:
                # Determine file type
                try:
                    with open(file_path, 'r', encoding='utf-8') as file:
                        code = file.read()
                    
                    # Guess the language/file type
                    try:
                        lexer = guess_lexer_for_filename(file_path, code)
                        file_type = lexer.name
                    except Exception:
                        file_type = os.path.splitext(file_path)[1][1:] or 'unknown'
                    
                    review = review_code(code, file_path, file_type)
                    return {
                        "file_path": file_path,
                        "review": review
                    }
                
                except UnicodeDecodeError:
                    # Handle binary files
                    return {
                        "file_path": file_path,
                        "review": json.dumps({
                            "error": "Binary file or unsupported encoding"
                        }, indent=2)
                    }
            except Exception as e:
                return {
                    "file_path": file_path,
                    "review": json.dumps({
                        "error": f"Error reviewing file: {str(e)}"
                    }, indent=2)
                }

        def generate_report(file_reviews):
            # Create a comprehensive markdown report
            report = "# <CodeSense?>\n\n"
            
            if not file_reviews:
                report += "No files were reviewed.\n"
                return report
            
            report += f"## Overview\n\n**Files Reviewed:** {len(file_reviews)}\n\n"
            
            for review_data in file_reviews:
                report += f"### File: `{review_data['file_path']}`\n\n"
                
                # Try to parse the review JSON and create a readable markdown
                try:
                    review_json = json.loads(review_data['review'])
                    
                    # Metrics section
                    if 'metrics' in review_json:
                        metrics = review_json['metrics']
                        report += "#### Metrics:\n"
                        report += f"- Overall Score: {metrics.get('overallScore', 'N/A')}\n"
                        report += f"- Quality Score: {metrics.get('qualityScore', 'N/A')}\n"
                        report += f"- Security Score: {metrics.get('securityScore', 'N/A')}\n"
                        report += f"- Performance Score: {metrics.get('performanceScore', 'N/A')}\n"
                        report += f"- Maintainability Score: {metrics.get('maintainabilityScore', 'N/A')}\n\n"
                    
                    # Recommendations section
                    if 'recommendations' in review_json:
                        recommendations = review_json['recommendations']
                        report += "#### Recommendations:\n"
                        report += f"**Priority:** {recommendations.get('priority', 'N/A')}\n\n"
                        if recommendations.get('items'):
                            for item in recommendations['items']:
                                report += f"- **{item.get('title', 'Unnamed Recommendation')}**\n"
                                report += f"  - Category: {item.get('category', 'N/A')}\n"
                                report += f"  - Severity: {item.get('severity', 'N/A')}\n"
                                report += f"  - Description: {item.get('description', 'N/A')}\n\n"
                    
                    # Full JSON for detailed inspection
                    report += "<details>\n"
                    report += "<summary>Full AI Review JSON</summary>\n\n"
                    report += "```json\n"
                    report += json.dumps(review_json, indent=2)
                    report += "\n```\n"
                    report += "</details>\n\n"
                
                except Exception as e:
                    # Fallback if JSON parsing fails
                    report += f"**Error parsing review:** {str(e)}\n\n"
                    report += "```json\n"
                    report += review_data['review']
                    report += "\n```\n\n"
            
            return report

        # Main execution
        reviews = []
        for root, _, files in os.walk('.'):
            for file in files:
                full_path = os.path.join(root, file)
                
                # Filter out non-source files and unwanted directories
                if not any(full_path.endswith(ext) for ext in ['.py', '.js', '.jsx', '.ts', '.tsx', '.java', '.cpp', '.c', '.go', '.rs', '.php', '.html', '.css']):
                    continue
                
                if any(exclude in full_path for exclude in ['node_modules', 'dist', 'build', 'coverage', '.git', '__pycache__']):
                    continue
                
                print(f"Reviewing {full_path}...")
                review = review_file(full_path)
                reviews.append(review)
        
        # Generate and save the report
        report = generate_report(reviews)
        os.makedirs('code-reviews', exist_ok=True)
        with open('code-reviews/review_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("Review completed. Report generated at code-reviews/review_report.md")
        EOF
    
    - name: Run Code Review
      run: |
        python3 review_code.py
    
    - name: Add Review Results to README
      run: |
        # Append the review report to the README file
        cat code-reviews/review_report.md >> README.md || true
        echo "Review results added to README.md"
    
    - name: Commit Review Results
      run: |
        git config user.name github-actions
        git config user.email github-actions@github.com
        git add README.md || true
        git commit -m "Add AI Code Review Results to README [skip ci]" || true
        git push || true